{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT 10"
      ],
      "metadata": {
        "id": "IHaNgDadnAs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a MLP model with 16 hidden layers using  \"fetch_lfw_people\" dataset from SKLearn and report performances using appropriate metrics. "
      ],
      "metadata": {
        "id": "3x79V3BknDRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivLo5d6Cm_Bw",
        "outputId": "b1d4a21c-413a-4d5f-e2cd-a788f737a1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13233, 2914) (13233,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "import pandas as pd\n",
        "dataset = fetch_lfw_people()\n",
        "x = dataset['data']\n",
        "y = dataset['target']\n",
        "print(x.shape, y.shape)             #printing shapes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "import numpy as np\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=1)"
      ],
      "metadata": {
        "id": "e1D1Mc4ipmpn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###    MultilayerPerceptron Classifier     ###\n",
        "from sklearn.metrics import accuracy_score, zero_one_loss,confusion_matrix, recall_score, f1_score\n",
        "np.random.seed(1)\n",
        "from sklearn.neural_network import MLPClassifier                                                 \n",
        "mlp = MLPClassifier(solver='lbfgs', activation ='relu',hidden_layer_sizes= 16 , max_iter = 300, random_state = 1)   \n",
        "mlp.fit(x_train,y_train)                                                                         \n",
        "pred3= mlp.predict(x_test)                                                                       \n",
        "print('Accuracy:',round(accuracy_score(y_test, pred3),4)*100)                                #Calculate Accuracy score\n",
        "print('Error:',round(zero_one_loss(y_test, pred3),4)*100)                                    #Calculate Error Score\n",
        "print('F-score:',round(f1_score(y_test,pred3,average='weighted'),4)*100)                     #Calculate F_score value\n",
        "print('Recall:', round(recall_score(y_test, pred3, average='weighted'),4)*100)               #Calculate Recall value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMBuRKddpl5w",
        "outputId": "e05c189c-3b61-4d99-ef3e-e3f52a8b875b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 7.23\n",
            "Error: 92.77\n",
            "F-score: 3.6799999999999997\n",
            "Recall: 7.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Analyse impact of different activation function and solver on the model. "
      ],
      "metadata": {
        "id": "WfuloGNHqTIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset['data']\n",
        "Y = dataset['target']"
      ],
      "metadata": {
        "id": "hgoL9oUxCUzG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "import numpy as np\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,random_state=1)"
      ],
      "metadata": {
        "id": "fb02znUVCOUb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###    MultilayerPerceptron Classifier with SGD solver     ###\n",
        "from sklearn.metrics import accuracy_score, zero_one_loss,confusion_matrix, recall_score, f1_score\n",
        "np.random.seed(1)\n",
        "from sklearn.neural_network import MLPClassifier                                                 \n",
        "mlp = MLPClassifier(solver='adam', activation = 'tanh', alpha=1 ,hidden_layer_sizes=(16,), random_state=42)   \n",
        "mlp.fit(X_train,Y_train)                                                                         \n",
        "predict = mlp.predict(X_test)                                                                       \n",
        "print('Accuracy:',round(accuracy_score(Y_test, predict),4)*100)                                #Calculate Accuracy score\n",
        "print('Error:',round(zero_one_loss(Y_test, predict),4)*100)                                    #Calculate Error Score\n",
        "print('F-score:',round(f1_score(Y_test,predict,average='weighted'),4)*100)                     #Calculate F_score value\n",
        "print('Recall:', round(recall_score(Y_test, predict, average='weighted'),4)*100)               #Calculate Recall value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC6DZkRAqoQG",
        "outputId": "4fb03f9d-377f-4db3-a19a-51a67a1b0e96"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 5.01\n",
            "Error: 94.99\n",
            "F-score: 1.03\n",
            "Recall: 5.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3. Explain your findings and report the best performance.\n",
        "\n",
        " The model performance is poor with 16 hidden layers Multi perceptron. The accuracy rate of both models with relu and tanh activation factor is almost same. The relu activation model provides better model performance than tanh activation model. "
      ],
      "metadata": {
        "id": "D8bgaAI9DEAd"
      }
    }
  ]
}